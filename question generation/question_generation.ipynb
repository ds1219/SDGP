{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "21c10a4b",
      "metadata": {
        "id": "21c10a4b",
        "outputId": "1874e575-a81e-409a-aa05-84b3fbe94b21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 35.7 s (started: 2023-03-09 16:42:36 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet transformers==4.8.1\n",
        "!pip install --quiet sentencepiece==0.1.95\n",
        "!pip install --quiet textwrap3==0.9.2\n",
        "!pip install --quiet strsim==0.0.3\n",
        "!pip install --quiet sense2vec==2.0.0\n",
        "!pip install --quiet ipython-autotime\n",
        "!pip install --quiet sentence-transformers==2.2.2\n",
        "%load_ext autotime\n",
        "\n",
        "from textwrap3 import wrap\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "model_max_length=512 \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summary_model = summary_model.to(device)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "#not sure what this part does\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_model = question_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bebaeef",
      "metadata": {
        "id": "2bebaeef"
      },
      "outputs": [],
      "source": [
        "def get_question(context,answer,model,tokenizer):\n",
        "    text = \"context: {} answer: {}\".format(context,answer)\n",
        "    encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
        "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "    outs = model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=72)\n",
        "\n",
        "\n",
        "    dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "\n",
        "    Question = dec[0].replace(\"question:\",\"\")\n",
        "    Question= Question.strip()\n",
        "    return Question\n",
        "\n",
        "for wrp in wrap(text, 150):\n",
        "    print (wrp)\n",
        "print (\"\\n\")\n",
        "\n",
        "for answer in keywords:\n",
        "    ques = get_question(text,answer,question_model,question_tokenizer)\n",
        "    print (ques)\n",
        "    print (answer.capitalize())\n",
        "    print (\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"In the year 1878 I took my degree of\n",
        "Doctor of Medicine of the University of\n",
        "London, and proceeded to Netley to go\n",
        "through the course prescribed for surgeons in the army. Having completed my studies\n",
        "there, I was duly attached to the Fifth Northumberland Fusiliers as Assistant Surgeon. The regiment\n",
        "was stationed in India at the time, and before I\n",
        "could join it, the second Afghan war had broken\n",
        "out. On landing at Bombay, I learned that my corps\n",
        "had advanced through the passes, and was already\n",
        "deep in the enemyâ€™s country. I followed, however,\n",
        "with many other officers who were in the same\n",
        "situation as myself, and succeeded in reaching Candahar in safety, where I found my regiment, and at\n",
        "once entered upon my new duties.\" \"\"\"\n",
        "\n",
        "def generate(text, keywords):\n",
        "  QA = []\n",
        "  for answer in keywords:\n",
        "    ques = get_question(text,answer,question_model,question_tokenizer)\n",
        "    QA.append(ques)\n",
        "  return QA\n",
        "  \n",
        "keywords = ['surgeons', 'Bombay', 'India', 'the regiment']\n",
        "\n",
        "Questions = generate(text, keywords)\n",
        "\n",
        "for i in range(0, len(keywords)):\n",
        "  print(f\"{keywords[i]} - {Questions[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6KPf4gmQ0Ma",
        "outputId": "c182176b-9b02-43e4-8adc-e4a6f8f41bac"
      },
      "id": "u6KPf4gmQ0Ma",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "surgeons - What was the course prescribed for in the army?\n",
            "Bombay - Where did I learn that my corps had advanced through the passes?\n",
            "India - Where was the Fifth Northumberland Fusiliers stationed?\n",
            "the regiment - Who was stationed in India at the time?\n",
            "time: 23.5 s (started: 2023-03-09 16:54:32 +00:00)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}