{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e78d311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-03-09 18:41:45 +05:30)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --quiet flashtext==2.7\n",
    "#!pip install git+https://github.com/boudinfl/pke.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21c10a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 2.2.2 requires huggingface-hub>=0.4.0, but you have huggingface-hub 0.0.12 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.45 s (started: 2023-03-09 18:40:36 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet transformers==4.8.1\n",
    "!pip install --quiet sentencepiece==0.1.95\n",
    "!pip install --quiet textwrap3==0.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aac0f463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.98 s (started: 2023-03-09 18:42:06 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet strsim==0.0.3\n",
    "!pip install --quiet sense2vec==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39cd65f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-03-09 13:24:13 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3796523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10 s (started: 2023-03-09 18:42:21 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7017233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
      "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
      "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
      "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
      "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
      "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
      "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\"\n",
      "\n",
      "\n",
      "time: 16 ms (started: 2023-03-09 13:28:25 +05:30)\n"
     ]
    }
   ],
   "source": [
    "from textwrap3 import wrap\n",
    "\n",
    "text = \"\"\"A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
    "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
    "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
    "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
    "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
    "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
    "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\" \"\"\"\n",
    "for wrp in wrap(text, 150): #converts the text to a string\n",
    "    print (wrp) #remove this later\n",
    "print (\"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27c5647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.06 s (started: 2023-03-09 13:29:23 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "model_max_length=512 \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary_model = summary_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "443165d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'def set_seed(seed: int):\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\nset_seed(42)\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-03-09 19:28:11 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#not sure what this part does\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "472ec465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Keshali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Keshali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Keshali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original Text >>\n",
      "A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
      "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
      "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
      "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
      "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
      "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
      "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\"\n",
      "\n",
      "\n",
      "Summarized Text >>\n",
      "A lion lay asleep in the forest, his great head resting on his paws. The timid little mouse ran across the lion's nose and begged him to let him go.\n",
      "\"please let me go and some day i will surely repay you,\" said the mouse. He was generous and finally let the mouse go; some days later, while stalking\n",
      "his prey, the lion was caught in an angry net.\n",
      "\n",
      "\n",
      "time: 3.17 s (started: 2023-03-09 19:30:24 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def postprocesstext (content):\n",
    "    final=\"\"\n",
    "    for sent in sent_tokenize(content):\n",
    "        sent = sent.capitalize()\n",
    "        final = final +\" \"+sent\n",
    "    return final\n",
    "\n",
    "#this part summurizes the text. its not necessary \n",
    "def summarizer(text,model,tokenizer):\n",
    "    text = text.strip().replace(\"\\n\",\" \")\n",
    "    text = \"summarize: \"+text\n",
    "    # print (text)\n",
    "    max_len = 512\n",
    "    encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "    outs = model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=3,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  min_length = 75,\n",
    "                                  max_length=300)\n",
    "\n",
    "\n",
    "    dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "    summary = dec[0]\n",
    "    summary = postprocesstext(summary)\n",
    "    summary= summary.strip()\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "summarized_text = summarizer(text,summary_model,summary_tokenizer)\n",
    "\n",
    "\n",
    "print (\"\\noriginal Text >>\")\n",
    "for wrp in wrap(text, 150):\n",
    "    print (wrp)\n",
    "print (\"\\n\")\n",
    "print (\"Summarized Text >>\")\n",
    "for wrp in wrap(summarized_text, 150):\n",
    "    print (wrp)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0eacc392",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_nouns_multipartite' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10168\\2666732255.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mimp_keywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummarized_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimp_keywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10168\\2666732255.py\u001b[0m in \u001b[0;36mget_keywords\u001b[1;34m(originaltext, summarytext)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_keywords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginaltext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummarytext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_nouns_multipartite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginaltext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"keywords unsummarized: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mkeyword_processor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeywordProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_nouns_multipartite' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2023-03-09 18:10:27 +05:30)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2183b4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a26e220728c4b1eb3b2f69dde57356f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb7f45207844657bee76ada98ef06e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2015d9536b94f55bf205d151f80ad5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943a7ebc35ba4872a19a0e496d53d6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 39min 17s (started: 2023-03-09 15:55:41 +05:30)\n"
     ]
    }
   ],
   "source": [
    "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_model = question_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bebaeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A lion lay asleep in the forest, his great head resting on his paws. The timid little mouse ran across the lion's nose and begged him to let him go.\n",
      "\"please let me go and some day i will surely repay you,\" said the mouse. He was generous and finally let the mouse go; some days later, while stalking\n",
      "his prey, the lion was caught in an angry net.\n",
      "\n",
      "\n",
      "What animal lay asleep in the forest?\n",
      "Lion\n",
      "\n",
      "\n",
      "Who begged the lion to let him go?\n",
      "Mouse\n",
      "\n",
      "\n",
      "Where did the lion lay asleep?\n",
      "Forest\n",
      "\n",
      "\n",
      "What was the lion caught in while stalking his prey?\n",
      "Net\n",
      "\n",
      "\n",
      "time: 1.67 s (started: 2023-03-09 18:27:35 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def get_question(context,answer,model,tokenizer):\n",
    "    text = \"context: {} answer: {}\".format(context,answer)\n",
    "    encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "    outs = model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  max_length=72)\n",
    "\n",
    "\n",
    "    dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "\n",
    "\n",
    "    Question = dec[0].replace(\"question:\",\"\")\n",
    "    Question= Question.strip()\n",
    "    return Question\n",
    "\n",
    "\n",
    "\n",
    "for wrp in wrap(summarized_text, 150):\n",
    "    print (wrp)\n",
    "print (\"\\n\")\n",
    "keywords = ['lion', 'mouse', 'forest', 'net']\n",
    "for answer in keywords:\n",
    "    ques = get_question(summarized_text,answer,question_model,question_tokenizer)\n",
    "    print (ques)\n",
    "    print (answer.capitalize())\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3992c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
